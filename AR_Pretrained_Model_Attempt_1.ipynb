{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:00.987534Z","iopub.execute_input":"2022-01-31T09:24:00.988205Z","iopub.status.idle":"2022-01-31T09:24:01.018378Z","shell.execute_reply.started":"2022-01-31T09:24:00.988120Z","shell.execute_reply":"2022-01-31T09:24:01.017137Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = \"../input/tensorflow-great-barrier-reef/train_images\"\nHEIGHT, WIDTH = 720, 1280\nimage_size = 640\n\nvid0_path = \"../input/tensorflow-great-barrier-reef/train_images/video_0\"\nvid1_path = \"../input/tensorflow-great-barrier-reef/train_images/video_1\"\nvid2_path = \"../input/tensorflow-great-barrier-reef/train_images/video_2\"\nvid_paths = [vid0_path, vid1_path, vid2_path]\n\nvid0_ls = [os.path.join(vid0_path,f) for f in os.listdir(vid0_path)]\nvid0_ls = sorted(vid0_ls, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\n\nvid1_ls = [os.path.join(vid1_path,f) for f in os.listdir(vid1_path)]\nvid1_ls = sorted(vid1_ls, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\n\nvid2_ls = [os.path.join(vid2_path,f) for f in os.listdir(vid2_path)]\nvid2_ls = sorted(vid2_ls, key=lambda x: int(\"\".join([i for i in x if i.isdigit()])))\nfiles_ls = [vid0_ls, vid1_ls, vid2_ls]\n\ntrain_df = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\",\n                       sep = r',', skipinitialspace = True)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:01.025310Z","iopub.execute_input":"2022-01-31T09:24:01.025603Z","iopub.status.idle":"2022-01-31T09:24:01.620062Z","shell.execute_reply.started":"2022-01-31T09:24:01.025566Z","shell.execute_reply":"2022-01-31T09:24:01.619334Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(vid0_ls[:3])\nprint(\"\\n\",files_ls[0][:3])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:01.622932Z","iopub.execute_input":"2022-01-31T09:24:01.623152Z","iopub.status.idle":"2022-01-31T09:24:01.629453Z","shell.execute_reply.started":"2022-01-31T09:24:01.623126Z","shell.execute_reply":"2022-01-31T09:24:01.628679Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"len(files_ls[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:01.631636Z","iopub.execute_input":"2022-01-31T09:24:01.632503Z","iopub.status.idle":"2022-01-31T09:24:01.642360Z","shell.execute_reply.started":"2022-01-31T09:24:01.632471Z","shell.execute_reply":"2022-01-31T09:24:01.641658Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:01.643834Z","iopub.execute_input":"2022-01-31T09:24:01.644409Z","iopub.status.idle":"2022-01-31T09:24:01.663234Z","shell.execute_reply.started":"2022-01-31T09:24:01.644356Z","shell.execute_reply":"2022-01-31T09:24:01.662521Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#### Helper functions","metadata":{}},{"cell_type":"code","source":"def get_oldpath(x):\n    if x.video_id == 0:\n        path = os.path.join(vid0_path,str(x.video_frame)+\".jpg\")\n    elif x.video_id == 1:\n        path = os.path.join(vid1_path,str(x.video_frame)+\".jpg\")\n    else:\n        path = os.path.join(vid2_path,str(x.video_frame)+\".jpg\")\n        \n    return path\n\ndef get_newpath(x):\n    filename = f\"{x.video_id}_{x.video_frame}.jpg\"\n    return os.path.join(\"./dataset\", filename)\n\ndef get_filename(x):\n    return f\"{x.video_id}_{x.video_frame}.jpg\"","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:01.664853Z","iopub.execute_input":"2022-01-31T09:24:01.665315Z","iopub.status.idle":"2022-01-31T09:24:01.672043Z","shell.execute_reply.started":"2022-01-31T09:24:01.665280Z","shell.execute_reply":"2022-01-31T09:24:01.671343Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import ast\nfrom tqdm import tqdm\nimport shutil\n\ntrain_df = train_df[train_df.annotations != \"[]\"]\ntrain_df[\"annotations\"] = train_df[\"annotations\"].map(lambda x : ast.literal_eval(x))\n\ntrain_df[\"filepath\"] = train_df.apply(lambda x : get_oldpath(x), axis=1)\ntrain_df[\"newpath\"] = train_df.apply(lambda x : get_newpath(x), axis=1)\ntrain_df[\"filename\"] = train_df.apply(lambda x : get_filename(x), axis=1)\n\nos.makedirs(\"./dataset\",exist_ok=True)\n\nfor i in tqdm(range(len(train_df))):\n    src = train_df.iloc[i][\"filepath\"]\n    dst = train_df.iloc[i][\"newpath\"]\n    if os.path.exists(dst)==False:\n        shutil.copy(src,dst)\n    \ntrain_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:01.673532Z","iopub.execute_input":"2022-01-31T09:24:01.673856Z","iopub.status.idle":"2022-01-31T09:24:57.955665Z","shell.execute_reply.started":"2022-01-31T09:24:01.673816Z","shell.execute_reply":"2022-01-31T09:24:57.954270Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Main Dataframe","metadata":{}},{"cell_type":"code","source":"df = train_df\ndf = df.explode(\"annotations\")\n\ndf[\"width\"] = [WIDTH]*len(df)\ndf[\"height\"] = [HEIGHT]*len(df)\ndf[\"label\"] = [\"starfish\"]*len(df)\n\ndf[\"xmin\"] = df.apply(lambda x : x.annotations[\"x\"], axis=1)\ndf[\"ymin\"] = df.apply(lambda x : x.annotations[\"y\"], axis=1)\ndf[\"xmax\"] = df.apply(lambda x : x.annotations[\"x\"]+x.annotations[\"width\"], axis=1)\ndf[\"ymax\"] = df.apply(lambda x : x.annotations[\"y\"]+x.annotations[\"height\"], axis=1)\n\ndf.loc[df[\"xmax\"] > 1280, \"xmax\"] = 1280\ndf.loc[df[\"ymax\"] > 720, \"ymax\"] = 720\n\ndf = df.drop([\"video_id\",\"sequence\",\"video_frame\",\"sequence_frame\",\"image_id\",\"annotations\",\"filepath\",\"newpath\"], axis=1)\ndf = df.reset_index(drop=True)\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:57.957756Z","iopub.execute_input":"2022-01-31T09:24:57.958456Z","iopub.status.idle":"2022-01-31T09:24:59.278753Z","shell.execute_reply.started":"2022-01-31T09:24:57.958361Z","shell.execute_reply":"2022-01-31T09:24:59.277974Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as npimg\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:59.282626Z","iopub.execute_input":"2022-01-31T09:24:59.284538Z","iopub.status.idle":"2022-01-31T09:24:59.574923Z","shell.execute_reply.started":"2022-01-31T09:24:59.284499Z","shell.execute_reply":"2022-01-31T09:24:59.574072Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def draw_annotations(spot_fish_img, img_row):\n    x = df[df['filename']==img_row[\"filename\"]]\n    print(f\"Number of starfish found is {len(x)}\")\n    for index in x.index:\n        spot_fish_img = cv2.rectangle(spot_fish_img, (x['xmin'][index], x['ymin'][index]),\n                  (x['xmax'][index], x['ymax'][index]), (255,255,0), 2)\n    return spot_fish_img","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:59.580335Z","iopub.execute_input":"2022-01-31T09:24:59.580660Z","iopub.status.idle":"2022-01-31T09:24:59.592570Z","shell.execute_reply.started":"2022-01-31T09:24:59.580622Z","shell.execute_reply":"2022-01-31T09:24:59.591867Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"img_row = df.iloc[random.randint(0, len(df))]\nimg_row","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:59.597276Z","iopub.execute_input":"2022-01-31T09:24:59.599837Z","iopub.status.idle":"2022-01-31T09:24:59.613022Z","shell.execute_reply.started":"2022-01-31T09:24:59.599799Z","shell.execute_reply":"2022-01-31T09:24:59.612334Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"original_img_path = os.path.join(\"./dataset\", img_row['filename'])\noriginal_img = npimg.imread(original_img_path)\n\nfig, axs = plt.subplots(1, 1, figsize=(15, 10))\nfig.tight_layout()\n\naxs.imshow(original_img)\naxs.set_title('Original Image')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:24:59.616530Z","iopub.execute_input":"2022-01-31T09:24:59.616719Z","iopub.status.idle":"2022-01-31T09:25:00.670549Z","shell.execute_reply.started":"2022-01-31T09:24:59.616696Z","shell.execute_reply":"2022-01-31T09:25:00.668073Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"spot_fish_img = original_img.copy()\ndraw_annotations(spot_fish_img, img_row)\n\nfig, axs = plt.subplots(1, 1, figsize=(15, 10))\nfig.tight_layout()\n\naxs.imshow(spot_fish_img)\naxs.set_title('spotfish Image')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:25:00.671555Z","iopub.execute_input":"2022-01-31T09:25:00.671767Z","iopub.status.idle":"2022-01-31T09:25:01.537508Z","shell.execute_reply.started":"2022-01-31T09:25:00.671738Z","shell.execute_reply":"2022-01-31T09:25:01.536839Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Data Modelling","metadata":{}},{"cell_type":"markdown","source":"Ref: https://www.kaggle.com/khanhlvg/cots-detection-w-tensorflow-object-detection-api\n\nLoad data: cots-detection-w-tensorflow-object-detection-api","metadata":{}},{"cell_type":"code","source":"import sys\nimport tensorflow as tf\n\nMODEL_DIR = '../input/cots-detection-w-tensorflow-object-detection-api/cots_efficientdet_d0'\n\ntf.keras.backend.clear_session()\ndetect_fn_tf_odt = tf.saved_model.load(os.path.join(os.path.join(MODEL_DIR, 'output'), 'saved_model'))\n\n#IMG_SIZE = (720, 1280)\n#IMG_SHAPE = IMG_SIZE + (3,)\n#detect_fn_tf_odt = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n#                                               include_top=False,\n#                                               weights='imagenet')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:25:01.538540Z","iopub.execute_input":"2022-01-31T09:25:01.539148Z","iopub.status.idle":"2022-01-31T09:25:36.573660Z","shell.execute_reply.started":"2022-01-31T09:25:01.539105Z","shell.execute_reply":"2022-01-31T09:25:36.572924Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nDETECTION_THRESHOLD = 0.1\n\ntest_img_row = df.iloc[random.randint(0, len(df))]\ntest_img_path = os.path.join(\"./dataset\", test_img_row['filename'])\n\nimage_np = np.array(Image.open(test_img_path))\n#print(image_np.shape)\n\ninput_tensor = np.expand_dims(image_np, 0)\ndetections = detect_fn_tf_odt(input_tensor)\n\nnum_detections = detections['num_detections'][0].numpy().astype(np.int32)\npredictions = []\nfor index in range(num_detections):\n    score = detections['detection_scores'][0][index].numpy()\n    if score < DETECTION_THRESHOLD:\n            continue\n    bbox = detections['detection_boxes'][0][index].numpy()\n    y_min = int(bbox[0] * HEIGHT)\n    x_min = int(bbox[1] * WIDTH)\n    y_max = int(bbox[2] * HEIGHT)\n    x_max = int(bbox[3] * WIDTH)\n\n    bbox_width = x_max - x_min\n    bbox_height = y_max - y_min\n\n    #predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n    predictions.append([score, x_min, y_min, bbox_width, bbox_height])\n#print('Prediction:', ', '.join(predictions))\n#print('Prediction:', predictions)\n\ntest_img = npimg.imread(test_img_path)\nspot_fish_img = test_img.copy()\ndraw_annotations(spot_fish_img, test_img_row)\n\nfor x in predictions:\n    spot_fish_img = cv2.rectangle(spot_fish_img, (x[1], x[2]), (x[1]+x[3], x[2]+x[4]),(255, 0, 0), 1)\n\nfig, axs = plt.subplots(1, 1, figsize=(15, 10))\n#fig.tight_layout()\n\naxs.imshow(spot_fish_img)\naxs.set_title('spotfish Image')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-31T09:31:37.613542Z","iopub.execute_input":"2022-01-31T09:31:37.613814Z","iopub.status.idle":"2022-01-31T09:31:38.394423Z","shell.execute_reply.started":"2022-01-31T09:31:37.613778Z","shell.execute_reply":"2022-01-31T09:31:38.393403Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}